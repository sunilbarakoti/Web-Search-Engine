Web Audio Processing: Use Cases Requirements Web Audio Processing: Use Cases Requirements W3C Working Group Note January version: http://www.w3.org/TR/2013/NOTE-webaudio-usecases-20130129/ Latest published version: http://www.w3.org/TR/webaudio-usecases/ Previous version: http://www.w3.org/TR/2012/WD-webaudio-usecases-20121004/ Latest editor's draft: https://dvcs.w3.org/hg/audio/raw-file/tip/reqs/Overview.html Editors: Joe Berkovitz, Noteflight Olivier Thereaux, British Broadcasting Corporation Copyright © W3C® ERCIM, Keio), Rights Reserved. W3C liability, trademark document use rules apply. Abstract document series scenarios list requirements guiding work W3C Audio Working Group development web API processing synthesis audio web. Status Document section status document time publication. Other documents supersede document. list current W3C publications latest revision technical report be found W3C technical reports index http://www.w3.org/TR/. document was published Audio Working Group Working Group Note. wish make comments regarding document, please send public-audio@w3.org archives). comments are welcome. Publication Working Group Note not imply endorsement W3C Membership. draft document be updated, replaced obsoleted other documents time. inappropriate cite document other work progress. document was produced group operating February W3C Patent Policy. W3C public list patent disclosures made connection deliverables group; page also instructions disclosing patent. individual actual knowledge patent individual Essential Claim(s) disclose information accordance section W3C Patent Policy. Table Contents Introduction Web Audio Scenarios Video Chat Application 3D game music convincing sound effects Online music production tool Online radio broadcast Music Creation Environment Sampled Instruments Connected DJ booth Playful sonification user interfaces Podcast flight Short film director's commentary audio description Web-based guitar practice service User Control Audio A. Acknowledgements Introduction future web sound was, essence, mission W3C Audio Working Group was chartered early features required advanced interactive applications including ability process synthesize audio". Bringing audio processing synthesis capabilities Open Web Platform allow developers re-create well-loved audio software open web add great sound web games applications; also enable web developers reinvent world audio music making more connected, linked social. document attempts describe scenarios considered W3C Audio Working Group work define Web Audio technologies. Not intended be comprehensive list things Web Audio standards make possible, nevertheless attempts document number key applications audio Web Audio standards enable, provide basis discussion desired architecture Web Audio standards, offer examples early uses technology, then be used gather feedback draft standard, extract technical architectural requirements Web Audio APIs libraries built Notes Implementation Considerations sections note constructs Web Audio API Working Draft apply. Whenever possible, document note features are yet be implemented documented specification 02 August Web Audio Scenarios section introduce number scenarios involving use Web Audio processing synthesis technologies, discuss implementation architectural considerations. Video Chat Application people have joined three-way conversation web application. see other participants split windows, hear voice sync video. application simple interface control incoming audio video other participants: time, user mute incoming streams, control overall sound volume, mute continuing send live video stream application. Advanced controls are also available. option panel, user ability adapt incoming sound taste graphic equalizer interface, well number filters voice enhancement, feature be useful people hearing difficulties, imperfect listening environments, compensate poor transmission environments. option user change spatialization voices interlocutors; default binaural mix matching disposition split-windows screen, interface makes possible reverse left-right balance, make other participants appear closer further apart. makers chat applications also offer version users distort speed, other effects) voice. are considering adding option default software, such feature also be used protect participants' privacy contexts. Notes Implementation Considerations processing capabilities needed scenario include: Mixing spatialization several sound sources Controlling gain volume control) several audio sources Filtering voice enhancement) Modifying pitch speed sound sources scenario also good example need audio capture line internal microphone other inputs). expect be provided HTML Media Capture. first scenario WebRTC's Use Cases Requirements document been strong inspiration scenario. Most technology, described be covered Web Real-Time Communication API. scenario however, need integrate audio processing handling RTC streams, technical requirement processing audio signal ends user's voice output correspondents' conversation). Speed changes are currently unsupported Web Audio API. 3D game music convincing sound effects commuter playing 3D first-person adventure game mobile device. game built entirely using open web technologies, rich, convincing sound piped commuter's stereo headphones. soon game starts, musical background starts, loops seamlessly, transitions smoothly music track player house. music generated live, state game: tempo, time signature, note properties envelopes change depending health level characters actions. walking corridor, player hear muffled sound ticking grandfather's clock. Following direction sound entering large hall, sound clock clear, reverberating large hall. time, sound clock spatialized real-time based position player's character room clock) current camera angle. soundscape changes, bringing more somber, scary atmosphere scene: once full orchestral underscore slowly reduced, instrument instrument, lonely echoing cello. player firearm. Suddenly, giant snake springs corner, hissing becoming little louder snake turns head player. weapon fires touch key, player hear sound bullets near-perfect synchronization firing, well sound bullets ricocheting walls. sounds are played immediately player presses key, action video frame rate remain smooth even lot sounds being fired, echoing ricocheting, sound impacts, etc) are played same time. snake now dead, many flies gather player's character, buzzing zooming virtual space room. Notes Implementation Considerations Developing soundscape game described benefit modular, node based approach audio processing. scenario, processing needs happen number sources same time room effects) others mixing spatialization) need happen per-source basis. graph-based API makes very easy envision, construct control necessary processing architecture, ways be possible other kinds APIs, more difficult implement. fundamental AudioNode construct Web Audio API supports approach. single looping music background be created today HTML5 <audio> element, ability transition smoothly musical background additional capabilities are found Web Audio API including sample-accurate playback scheduling automated cross-fading multiple sources. Related API features include AudioBufferSourceNode.start() AudioParam.setValueAtTime(). musical background game not only seamless looping transitioning full tracks, also automated creation generative music basic building blocks algorithms music generated live, state game"), well creation evolution musical score multiple instrument tracks once full orchestral underscore slowly reduced, instrument instrument"). Related requirements such features are developed details Online music production tool Music Creation Environment Sampled Instruments scenarios. scenario many aspects creation credible soundscape. game character evolving virtual three-dimensional environment soundscape times spatialized: panning model be used spatialize sound sources game obstruction occlusion modeling used muffle sound clock going walls, sound flies buzzing need Doppler Shift simulation sound believable supported AudioPanningNode). listener's position part 3D model well soundscape changes small room large hall, game benefits simulation acoustic spaces, possibly use convolution engine high quality room effects supported ConvolverNode Web Audio API. Many sounds scenario are triggered events game, need be played low latency. sound bullets are fired ricochet walls, particular, illustrate requirement basic polyphony high-performance playback processing many sounds. are supported general ability Web Audio API include many sound-generating nodes independent scheduling high-throughput native algorithms. Online music production tool music enthusiast musical composition audio media clips using web-based Digital Audio Workstation application. Audio are arranged timeline representing multiple tracks audio. track's volume, panning, effects be controlled separately. Individual tracks be muted soloed preview various combination tracks given moment. Audio effects be applied per-track inline effects. Additionally, track send signal more global send effects are shared tracks. Sub-mixes various combinations tracks be made, final mix bus controls overall volume mix, have additional insert effects. Insert send effects include dynamics compressors multi-band), extremely high-quality reverberation, filters such parametric, low-shelf, high-shelf, graphic EQ, etc. Also included are various kinds delay effects such ping-pong delays, BPM-synchronized delays feedback. Various kinds time-modulated effects are available such chorus, phasor, resonant filter sweeps, BPM-synchronized panners. Distortion effects include subtle tube simulators, aggressive bit decimators. effect own UI adjusting parameters. Real-time changes parameters be made mouse) audible results heard perceptible lag. Audio clips be arranged timeline high-degree precision sample accurate playback). Certain clips be repeated loops containing beat-based musical material, are synchronized other such looped clips according certain musical tempo. turn, be synchronized sequences controlling real-time synthesized playback. values volume, panning, send levels, parameter effect be changed time, displayed controlled powerful UI dealing automation curves. curves be arbitrary be used, example, control volume fade-ins, filter sweeps, be synchronized time music synchronized). Visualizers be applied technical analysis signal. visualizers be simple displaying signal level VU meter, more complex such real-time frequency analysis, L/R phase displays. actual audio clips be arranged timeline are managed library available clips. be searched sorted variety ways high-efficiency. clips be cloud-based, local caching offers nearly instantaneous access glitch-free playback. final mix be rendered faster real-time then uploaded shared others. session representing clips, timeline, effects, automation, etc. also be shared others shared-mixing collaboration. Notes Implementation Considerations scenario details large number feature requirements typically expected professional audio software hardware. many advanced audio control capabilities such filtering, effects, dynamics compression control various audio parameters. Building such application only be reasonably possible technology control audio acceptable performance, particular real-time processing control audio parameters sample accurate scheduling sound playback. performance such key aspect scenario, probably be possible control buffer size underlying Audio API: allow users slower machines pick larger buffer setting not cause clicks audio stream. ability visualize samples processing benefits real-time time-domain frequency analysis, supplied Web Audio API's RealtimeAnalyzerNode. Clips be able be loaded memory fast playback. Web Audio API's AudioBuffer AudioBufferSourceNode interfaces address requirement. sound sources be purely algorithmic nature, such oscillators noise generators. ability generate sound precomputed dynamically computed arbitrary sound samples. Web Audio API's ability create AudioBuffer arrays numerical samples, coupled ability JavaScriptAudioNode supply numerical samples fly, address requirement. ability schedule audio clip playback effects parameter value changes advance essential support automated mixdown export audio file, audio rendering pipeline be able yield buffers sample frames directly, rather being forced audio device destination. Built-in codecs translate buffers standard audio file output formats are also desirable. Typical per-channel effects such panning, gain control, compression filtering be readily available native, high-performance implementation. Typical master bus effects such room reverb be readily available. Such effects are applied entire mix final processing stage. single ConvolverNode capable simulating wide range room acoustics. Online radio broadcast web-based online radio application supports one-to-many audio broadcasting various channels. broadcast channel separate user interfaces different pages. interface used broadcaster controlling radio show channel. second interface invited guests supply live audio show. third interface live online audience listening channel. broadcaster interface supports live recorded audio source selection well mixing sources. Audio sources include: local microphone prerecorded audio such jingles tracks music libraries remote microphone remote guest simple mixer broadcaster control volume, pan effects processing local remote audio source, blending single stereo output mix broadcast show's content. Indicators track level active source. mixer also automatic features make broadcaster's life easier, including ducking prerecorded audio sources local remote microphone source active. Muting sources causes automatic fast volume fade-out(in) avoid audio transients. broadcaster hear live monitor mix headphones, adjustable level monitoring local microphone. application aware prerecorded audio playing mix, audio track's descriptive metadata shown audience synchronization are hearing. guest interface supports single live audio source choice local microphone. audience interface channel's broadcast mix, also offers basic volume EQ control ability pause/rewind/resume live stream. Optionally, listener slow down content audio changing pitch, example aid understanding foreign language. advanced feature give audience control mix mix tracks sources created broadcaster be default, listener have ability create different mix. instance, case radio play mix voices, sound effects music, listener be offered interface control relative volume voices effects music, create binaural mix tailored specifically taste. Such feature provide valuable personalization radio experience, well significant accessibility enhancements. Notes Implementation Considerations Video Chat Application scenario, streaming local device discovery access scenario are handled Web Real-Time Communication API. local audio processing scenario requirement RTC streams Web Audio be tightly integrated. Incoming MediaStreams be able be exposed audio sources, audio destinations be able yield outgoing RTC stream. example, broadcaster's browser set incoming MediaStreams microphones, remote participants, etc., locally processes audio graph AudioNodes, output outgoing MediaStream representing live mix show. Building application application gain control, panning, audio effects blending multiple mono stereo audio sources yield stereo mix. relevant features API include AudioGainNode, ConvolverNode, AudioPannerNode. Noise gating output source's level minimum threshold) highly desirable microphone inputs avoid stray room noise being included broadcast mix. be implemented custom algorithm using JavaScriptAudioNode. drive visual feedback broadcaster audio source activity control automatic ducking, scenario needs way easily detect time-averaged signal level given audio source. Web Audio API not currently provide prepackaged way do be implemented custom processing ultra-low-pass filter built BiquadFilterNode. Ducking level multiple audio sources once, ability associate single dynamic audio parameter gain associated sources' signal paths. specification's AudioGain interface Smooth muting ability smoothly automate gain changes time interval, using browser-unfriendly coding techniques tight loops high-frequency callbacks. parameter automation features associated AudioParam are useful kind feature. Pausing resuming show audience side ability buffer data received audio sources processing graph, also send buffered data audio destinations. Speed changes are currently unsupported Web Audio API. Thus, functionality audio speed changing, custom algorithm, ability create custom audio transformations using browser programming language JavaScriptAudioNode). audio delivery slowed down, audio samples have be locally buffered application up allowed limit, continue be delivered incoming stream normal rate. standard way access set metadata properties media resources following W3C documents: Ontology Media Resources document core set metadata properties media resources, mappings elements set existing metadata formats. API Media Resources API developers convenient access metadata information stored different metadata formats. means access set metadata properties defined Ontology Media Resources specification. ability listeners create own mix rely possibility sending multiple tracks RTC stream. scope current WebRTC specification, MediaStream have multiple MediaStreamTracks. Music Creation Environment Sampled Instruments composer employing web-based application create edit musical composition live synthesized playback. user interface composing take number forms including conventional Western notation piano-roll style display. document be sonically rendered demand piece music, i.e. series precisely timed, pitched modulated audio events musician occasionally stops editing wishes hear playback score are working take stock work. point program sequenced playback portion document. simple effects such instrument panning room reverb are also applied more realistic satisfying effect. Compositions editor employ set instrument samples, i.e. pre-existing library recorded audio snippets. given snippet brief audio recording note played instrument specific known combination pitch, dynamics articulation. combinations library are necessarily limited number avoid bandwidth storage overhead. playback, editor simulate sound instrument playing part composition. done transforming available pre-recorded samples original pitch, duration volume match characteristics prescribed note composed music. per-note transformations also be scheduled be played times prescribed composition. playback moving cursor exact point music being heard moment. point user exports MP3 WAV file program other purpose. file same audio rendition score played interactively user requested earlier. Notes Implementation Considerations Instrument samples be able be loaded memory fast processing music rendering. pre-loaded audio snippets have one-to-many relationship objects Web Audio API representing specific notes, avoid duplicating same sample memory note composition rendered API's AudioBuffer AudioBufferSourceNode interfaces address requirement. be possible schedule large numbers individual events long period time, transformation original audio sample, degrading real-time browser performance. graph-based approach such Web Audio API makes construction given transformation practical, supporting simple recipes creating sub-graphs built sample's pre-loaded AudioBuffer. subgraphs be constructed scheduled be played future. approach supporting longer compositions, construction scheduling future events be kept up" periodic timer callbacks, avoid overhead creating huge graphs once. given sample be able be arbitrarily transformed pitch volume match note music. AudioBufferSourceNode's playbackRate attribute pitch-change capability, AudioGainNode volume be adjusted. given sample be able be arbitrarily transformed duration changing pitch) match note music. AudioBufferSourceNode's looping parameters provide sample-accurate start end loop points, allowing note arbitrary duration be generated even original recording be brief. Looped samples definition do not have clean ending. avoid abrupt glitchy cutoff end note, gain filter envelope be applied. Such envelopes normally follow exponential trajectory key time intervals life cycle note. AudioParam features Web Audio API conjunction AudioGainNode BiquadFilterNode support requirement. necessary coordinate visual display sequenced playback document, such moving cursor highlighting effect applied notes. need programmatically determine exact time offset performance sound being currently rendered computer's audio output channel. time offset turn, have well-defined relationship time offsets prior API requests schedule various notes various times. API such capability AudioContext.currentTime attribute. export audio file, audio rendering pipeline be able yield buffers sample frames directly, rather being forced audio device destination. Built-in codecs translate buffers standard audio file output formats are also desirable. Typical per-channel effects such stereo pan control be readily available. Panning sound output instrument channel appear occupy different spatial location output mix, adding greatly realism playback. Adding configuring Web Audio API's AudioPannerNode channel output path capability. Typical master bus effects such room reverb be readily available. Such effects are applied entire mix final processing stage. single ConvolverNode capable simulating wide range room acoustics. Connected DJ booth popular DJ playing live set, using popular web-based DJ software. web application perform club mixing, well online, tens thousands joining live enjoy set. DJ-deck web interface offers typical features decks turntables. first track playing sound sent sound system club streamed web browsers fans world, DJ be able quickly select several other track, play headphones affecting main audio output application, match track currently playing mix pausing, skipping forward back pitch/speed change. application automate lot work: measuring beat current track chosen track BPM, automatically slow down second track, even position match beats currently playing. Once correct match reached, DJ be able start playing track main audio output, immediately slowly changing volume controls track. uses cross fader let new song blend old eventually completely so only new song playing. illusion song never ended. other end, fans listening set be able watch video DJ mixing, accompanied graphic visualization music, picked variety choices: spectrum analysis, level-meter view number 2D 3D abstract visualizations displayed overlaid DJ video. Notes Implementation Considerations many other scenarios document, expected APIs such Web Real-Time Communication API be used streaming audio video number clients. specific requirements illustrated scenario ability have different outputs sound: headphones, music stream sent clients. typical web-friendly hardware, be difficult impossible implement considering audio destinations, seldom have allow sound outputs be used same time. indeed, current Web Audio API draft, given AudioContext only use AudioDestinationNode destination. However, consider headphones are audio output, streaming DJ set not typical audio destination outgoing MediaStream passed WebRTC API, be possible implement scenario, sending output headphones stream gradually sending sound other affecting exact state playback processing source. Web Audio API, be achieved using createMediaStreamDestination() interface. scenario makes heavy usage audio analysis capabilities, automation purposes detection beat matching) visualization level other abstract visualization modes). requirement pitch/speed change are not currently covered Web Audio API's native processing nodes. Such processing probably have be handled custom processing nodes. Playful sonification user interfaces child visiting social website designed kids. playful, colorful HTML interface accompanied sound effects played child hovers clicks elements page. example, filling form sound typewriter be heard child types form field. sounds are spatialized have different volume depending child page. action triggers download visualized progress bar, gradually rising pitch sound download sound played download complete. Notes Implementation Considerations web UI many sound effects, controls are embedded site's pages using standard web technology such HTML form elements CSS stylesheets. JavaScript event handlers be attached elements, causing graphs AudioNodes be constructed activated produce sound output. Modularity, spatialization mixing play important role scenario, others document. Various effects be achieved programmatic variation sounds using Web Audio API. download progress smoothly vary pitch AudioBufferSourceNode's playbackRate using exponential ramp function, more realistic typewriter sound be achieved varying output filter's frequency based keypress's character code. future version CSS, stylesheets be able support simple types sonification, such attaching key" sound HTML textarea element sound HTML button. be thought extension visual skinning concepts already embodied style attributes such background-image. Podcast flight traveler subscribed podcast, previously downloaded audio book device using podcast's web-based application. audio files are stored locally device, giving simple convenient access episodic content user wishes listen. Sitting airplane 2-hour flight, podcast application HTML browser episode selected hours. application offers speed-up feature speech be delivered faster normal speed pitch distortion voices"). sets audition time hours order finish audio book landing. also sets sound control application Environment", causing sound be equalized greatest intelligibility noisy setting such airplane. Notes Implementation Considerations Local audio be downloaded, stored retrieved using HTML File API. scenario special audio transformation compress duration speech affecting overall timbre intelligibility. Web Audio API function natively supported be accomplished attaching custom processing code JavaScriptAudioNode. Environment" setting be accomplished equalization features Web Audio API such BiquadFilterNode ConvolverNode. Short film director's commentary audio description video editor using online editing tool refine soundtrack short film. Once video ready, work production team prepare audio description scenes make video work more accessible people sight impairments. video director also planning add audio commentary track explain creative process film. Using online tool, video editor extracts existing recorded vocals video stream, levels other modifications audio stream. also several songs, including orchestral background pop songs, different parts film soundtrack. Several Foley effects doors opening closing, etc.) are also added make soundscape scene complete. editing, online tool ensure audio video playback are synchronized, allowing editor insert audio samples right time. length songs slightly different video segment matching synchronize slightly speeding up slowing down audio track. final soundtrack mixed down final soundtrack, added video replacement original audio track, synced video track. Once audio description commentary are recorded, film, displayed HTML web page, be played original audio track video container) audio commentary tracks loaded different source synchronized video playback. audio commentary track, main track volume reduced gradually smoothly brought back full volume commentary description track silent. visitor switch audio tracks fly, affecting video playback. Pausing video playback also commentary track, then remains sync playback resumes. Notes Implementation Considerations scenario many ways, fairly similar number others already discussed document. ability lay number sources mix consistent soundtrack subject Online music production tool scenario, effects such ducking have already been discussed Online radio broadcast scenario. Essentially, use case need do things sync video. context open web platform, means audio processing API integrate HTML5 MediaController interface. Web-based guitar practice service serious guitar player uses web-based tool practice new tune. Connecting USB microphone pair headphones computer, guitarist able tune acoustic guitar using graphical interface set metronome practice session. mix more backing tracks be optionally selected guitarist play metronome present. practice session, microphone audio analyzed determine guitarist playing correct notes tempo, visual feedback provided graphical interface guitar tablature sheet music superimposed highlighting. guitarist's performance session recorded, optionally mixed audio backing-track mix. conclusion session, performance be saved various file formats uploaded online social music service sharing commentary other users. Notes Implementation Considerations audio input guitarist's performance, aurally synchronized guitarist current audio output. scenario input be analyzed correct rhythmic pitch content. Such algorithm be implemented JavaScriptAudioNode. Analysis performance turn measurement real-time latency audio input output, so algorithm analyzing live performance know temporal relationship given output sample metronome backing track) given input sample guitarist playing output). latencies are unpredictable system be hard-coded. Currently Web Audio API such support. scenario uses mixture sound sources including live microphone input, synthesized metronome set pre-recorded audio backing tracks are synced fixed tempo). mixing sources browser's audio output be accomplished combination instances AudioGainNode AudioPannerNode. live input microphone access, anticipated be available HTML Media Capture bridged AudioNode interface. Pre-recorded backing tracks be loaded AudioBuffers used sample-accurate synced sources wrapping AudioBufferSourceNode instances. Metronome synthesis be accomplished variety means provided Web Audio API. approach, implementer use Oscillator square-wave source generate metronome sound. timer callback repeatedly runs low frequency maintain pool instances scheduled occur future beats music be sample-accurately synced offsets backing tracks given lock-step timing Web Audio API). Programmatic output recorded session's audio buffer be accomplished files HTML5 File API) upload streams MediaStreams HTTP). scenario use more encoders buffered data yield supported audio file formats. Native audio-to-file encoding not currently supported Web Audio API thus need be implemented JavaScript. User Control Audio programmer create browser extension allow user control volume audio. extension let user control audio volume per-tab basis, kill audio playing completely. extension developer wishes make sure killing audio done way care garbage collection. features sometimes requested extension are ability limit audio volume acceptable level, tab globally. operating systems allow developer also extension mute pause sound critical system sound being played. Notes Implementation Considerations function likely combine usage browser-specific extension API Web Audio API. way implement scenario be use browser-dependent API iterate list window objects, then window object iterate list active AudioContexts manage volume more conveniently, manage kind master audio volume window). latter approaches are currently supported Web Audio API. ability mute pause sounds Operating System fires critical system sound modelled feature existing Operating Systems automatically mute applications outputting system sound. such, not involve specific requirement Web Audio API. However, operating systems implement such feature, Web Audio apps want be notified muting act accordingly pause, etc). therefore be requirement Web Audio API provide such event handler. A. Acknowledgements document result work W3C Audio Working Group. Members working group, time publication, included: Bateman, Adrian Corporation); Berkovitz, Joe expert); Cardoso, Gabriel Carlson, Eric Inc.); Chen, Bin Inc.); Geelnard, Marcus Software); Goode, Adam Inc.); Gregan, Matthew Foundation); JÃ¤genstedt, Philip Software); Kalliokoski, Jussi expert); Lowis, Chris Broadcasting Corporation); MacDonald, Alistair Expert); Mandyam, Giridhar Innovation Center, Inc); Michel, Thierry Noble, Jer Inc.); O'Callahan, Robert Foundation); Olivier, Frank Corporation); Paradis, Matthew Broadcasting Corporation); Peraza Barreras, Jorge Armando Corporation); Raman, T.V. Inc.); Rogers, Chris Inc.); Schepers, Doug Shires, Glen Inc.); Smith, Michael Thereaux, Olivier Broadcasting Corporation); Wei, James Corporation); Wilson, Chris Young, Milan Communications, Inc.). people have contributed discussions public-audio@w3.org are also gratefully acknowledged. document was also heavily influenced earlier work audio working group others, including: list Use Cases" authored W3C Audio Incubator Group, predated W3C Audio Working Group use cases requirements Web RTC Scenarios Media Streams Processing 